{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This notebook is using to simulate a user that is chatting with the chatBot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import redis\n",
    "import time\n",
    "import os\n",
    "from uuid import uuid4\n",
    "from generative_retirver import settings\n",
    "\n",
    "from haystack.document_stores import ElasticsearchDocumentStore\n",
    "from haystack.nodes import PreProcessor\n",
    "from eda.src import config"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cretating Document store\n",
    "first run the docker-compose.yaml\n",
    "\n",
    "**> docker-compose up -d**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the host where Elasticsearch is running, default to localhost\n",
    "host = os.environ.get(\"ELASTICSEARCH_HOST\", \"localhost\")\n",
    "\n",
    "document_store = ElasticsearchDocumentStore(\n",
    "    host=host,\n",
    "    username=\"\",\n",
    "    password=\"\",\n",
    "    index=\"document\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_file_path = os.path.join(config.DATA_PROCESSED_PATH, \"json_dataset.json\")\n",
    "# Load the documents from the JSON file\n",
    "with open(json_file_path, \"r\") as f:\n",
    "    document_list = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "01fdfa732b5e400cbae235ae7f671221",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Preprocessing:   0%|          | 0/1 [00:00<?, ?docs/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create an instance of PreProcessor\n",
    "# Each document is divided into paragraphs of approximately 500 tokens.\n",
    "\n",
    "preprocessor = PreProcessor(\n",
    "    clean_empty_lines=True,\n",
    "    clean_whitespace=True,\n",
    "    clean_header_footer=True,\n",
    "    split_by=\"word\",\n",
    "    split_length=200,\n",
    "    split_overlap=10,\n",
    "    split_respect_sentence_boundary=False,\n",
    ")\n",
    "\n",
    "doc_processed = preprocessor.process(document_list)\n",
    "\n",
    "# clear the document store before loading documents\n",
    "document_store.delete_documents()\n",
    "\n",
    "# Upload documents to the document store\n",
    "document_store.write_documents(doc_processed)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load message broker redi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Connect to Redis and assign to variable `db``\n",
    "# Make use of settings.py module to get Redis settings like host, port, etc.\n",
    "db = redis.Redis(settings.REDIS_IP, settings.REDIS_PORT, db=settings.REDIS_DB_ID)\n",
    "db.ping()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def model_predict(json_name, query_number):\n",
    "    \"\"\"\n",
    "    Receives the name of the user_jason and queues the job into Redis.\n",
    "    Will loop until getting the answer from our retriver-generative service.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    json_name : str\n",
    "        Name for the json file with the user query.\n",
    "    query_number : int\n",
    "        Identifies the query within the json\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    answer, context : tuple(str, str)\n",
    "        Model generate an answer as a string and the context where found it\n",
    "    \"\"\"\n",
    "    \n",
    "    # Assign an unique ID for this job and add it to the queue.\n",
    "    # We need to assing this ID because we must be able to keep track\n",
    "    # of this particular job across all the services\n",
    "    job_id = str(uuid4())\n",
    "\n",
    "    # Create a dict with the job data we will send through Redis having the   \n",
    "    Out_dict = {\n",
    "        \"id\": job_id,\n",
    "        \"query_number\":query_number,\n",
    "        \"json_name\": json_name,\n",
    "    }\n",
    "    job_data = json.dumps(Out_dict)\n",
    "\n",
    "    # Send the job to the model service using Redis \n",
    "    db.lpush(settings.REDIS_QUEUE, job_data)\n",
    "\n",
    "    # Loop until we received the response from the retriver-generative model\n",
    "    while True:\n",
    "        # Attempt to get model predictions using job_id        \n",
    "        output = db.get(job_id)\n",
    "\n",
    "        # Check if the text was correctly processed by our model\n",
    "        if output is not None:\n",
    "            output = json.loads(output.decode(\"utf-8\"))\n",
    "            answer = output[\"answer\"]\n",
    "            context = output[\"context\"]\n",
    "\n",
    "            db.delete(job_id)\n",
    "            break\n",
    "\n",
    "        # Sleep some time waiting for model results\n",
    "        time.sleep(settings.SERVER_SLEEP)\n",
    "\n",
    "    return answer, context"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simulating a user\n",
    "first run in bash the retriver-generative model\n",
    "\n",
    "**> python .\\generative_retirver\\retriver_gen.py**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save documents in the file json_dataset.json\n",
    "def save_json(my_file,json_path):    \n",
    "    with open(json_path, \"w\") as f:\n",
    "        json.dump(my_file, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer query 1 [\"Cash equivalents are assets that are readily convertible to cash and have a maturity period of three months or less. In the given context, the company's cash and cash equivalents decreased by $12,352,000 from the beginning of the year to the end of the year.\"]\n",
      "Answer query 2 [\"The Consolidated Statements of Cash Flows for GENCOR INDUSTRIES, INC. show the company's cash flows from operating, investing, and financing activities, as well as the net increase or decrease in cash and cash equivalents for the years ended September 30, 2021 and 2020. The statements also include non-cash investing and financing activities.\"]\n",
      "Answer query 3 [\"There is no information provided in the given context regarding the revenues and expenses of the company. The context only discusses the company's expectations and beliefs, risks and uncertainties, and its core products.\"]\n",
      "Answer query 4 ['The context does not provide information on whether or not GENCOR INDUSTRIES has any debt.']\n"
     ]
    }
   ],
   "source": [
    "# create the user_json_file to save the user interaction\n",
    "json_user=[]\n",
    "job_id = str(uuid4())\n",
    "user_json_name = job_id +'.json'\n",
    "json_file_path = os.path.join(settings.UPLOAD_FOLDER, user_json_name)\n",
    "with open(json_file_path, \"w\") as f:\n",
    "    json.dump(json_user, f)\n",
    "\n",
    "# Get the query from user\n",
    "myquery = input(\"Please write your query: \")\n",
    "# read the json user\n",
    "#with open(json_file_path, \"r\") as f:\n",
    "#    json_user = json.load(f)\n",
    "\n",
    "# Recive queries\n",
    "cont=0\n",
    "while myquery:\n",
    "    if cont!= 0:\n",
    "        myquery = input(\"Please write your query: \")\n",
    "        if myquery=='exit':break\n",
    "\n",
    "    if myquery !='':\n",
    "        _json={'number':cont, 'query': myquery, 'answer':''}\n",
    "        json_user.append(_json)\n",
    "        save_json(json_user,json_file_path)\n",
    "\n",
    "        answer, context = model_predict(user_json_name, cont)        \n",
    "        json_user[cont]={'number':cont, 'query': myquery, 'answer':answer}\n",
    "        cont+=1\n",
    "        #json_user.append(_json)\n",
    "        save_json(json_user,json_file_path)\n",
    "                \n",
    "        print(\"Answer query\",cont, answer)\n",
    "    else:\n",
    "        print('No query detected')\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
