{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from haystack.document_stores import ElasticsearchDocumentStore\n",
    "import os\n",
    "from haystack import Pipeline\n",
    "from haystack.nodes import PreProcessor\n",
    "from src import download_data, config, preprocess_data_raw, preprocess_data_raw_2\n",
    "import os\n",
    "import json"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data for AWS bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket_name = config.BUCKET_NAME\n",
    "s3_folder = config.S3_FOLDER_URL\n",
    "local_dir = config.DATA_RAW_PATH\n",
    "\n",
    "# load data form AWS bucket and save in local_dir\n",
    "download_data.download_s3_folder(bucket_name, s3_folder, \n",
    "                                 local_dir=local_dir, \n",
    "                                 sample_size=10)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save data set as jason in .data/processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m preprocess_data_raw_2\u001b[39m.\u001b[39;49mconvert_pdf_jason(config\u001b[39m.\u001b[39;49mDATA_RAW_PATH, config\u001b[39m.\u001b[39;49mDATA_PROCESSED_PATH)\n",
      "File \u001b[1;32mc:\\Users\\jslug\\OneDrive\\Documents\\Anyone\\financial-advisor-chatbot\\eda\\src\\preprocess_data_raw_2.py:26\u001b[0m, in \u001b[0;36mconvert_pdf_jason\u001b[1;34m(pdf_directory, json_directory)\u001b[0m\n\u001b[0;32m     23\u001b[0m company_name \u001b[39m=\u001b[39m folder_name\n\u001b[0;32m     25\u001b[0m \u001b[39m# Convert PDF files into documents using Haystack\u001b[39;00m\n\u001b[1;32m---> 26\u001b[0m docs \u001b[39m=\u001b[39m convert_files_to_docs(dir_path\u001b[39m=\u001b[39;49mfolder_path)\n\u001b[0;32m     28\u001b[0m \u001b[39m# Processes each generated document\u001b[39;00m\n\u001b[0;32m     29\u001b[0m \u001b[39mfor\u001b[39;00m doc_pdf \u001b[39min\u001b[39;00m docs:\n",
      "File \u001b[1;32mc:\\Users\\jslug\\OneDrive\\Documents\\Anyone\\financial-advisor-chatbot\\.venv\\Lib\\site-packages\\haystack\\utils\\preprocessing.py:68\u001b[0m, in \u001b[0;36mconvert_files_to_docs\u001b[1;34m(dir_path, clean_func, split_paragraphs, encoding, id_hash_keys)\u001b[0m\n\u001b[0;32m     66\u001b[0m logger\u001b[39m.\u001b[39minfo(\u001b[39m\"\u001b[39m\u001b[39mConverting \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m, path)\n\u001b[0;32m     67\u001b[0m \u001b[39m# PDFToTextConverter, TextConverter, and DocxToTextConverter return a list containing a single Document\u001b[39;00m\n\u001b[1;32m---> 68\u001b[0m document \u001b[39m=\u001b[39m suffix2converter[suffix]\u001b[39m.\u001b[39;49mconvert(\n\u001b[0;32m     69\u001b[0m     file_path\u001b[39m=\u001b[39;49mpath, meta\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m, encoding\u001b[39m=\u001b[39;49mencoding, id_hash_keys\u001b[39m=\u001b[39;49mid_hash_keys\n\u001b[0;32m     70\u001b[0m )[\u001b[39m0\u001b[39m]\n\u001b[0;32m     71\u001b[0m text \u001b[39m=\u001b[39m document\u001b[39m.\u001b[39mcontent\n\u001b[0;32m     73\u001b[0m \u001b[39mif\u001b[39;00m clean_func:\n",
      "File \u001b[1;32mc:\\Users\\jslug\\OneDrive\\Documents\\Anyone\\financial-advisor-chatbot\\.venv\\Lib\\site-packages\\haystack\\nodes\\file_converter\\pdf.py:171\u001b[0m, in \u001b[0;36mPDFToTextConverter.convert\u001b[1;34m(self, file_path, meta, remove_numeric_tables, valid_languages, encoding, id_hash_keys, start_page, end_page, keep_physical_layout, sort_by_position, ocr, ocr_language, multiprocessing)\u001b[0m\n\u001b[0;32m    168\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mThe ocr parameter must be either \u001b[39m\u001b[39m'\u001b[39m\u001b[39mauto\u001b[39m\u001b[39m'\u001b[39m\u001b[39m or \u001b[39m\u001b[39m'\u001b[39m\u001b[39mfull\u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    169\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_tessdata()\n\u001b[1;32m--> 171\u001b[0m pages \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_read_pdf(\n\u001b[0;32m    172\u001b[0m     file_path,\n\u001b[0;32m    173\u001b[0m     sort_by_position\u001b[39m=\u001b[39;49msort_by_position,\n\u001b[0;32m    174\u001b[0m     start_page\u001b[39m=\u001b[39;49mstart_page,\n\u001b[0;32m    175\u001b[0m     end_page\u001b[39m=\u001b[39;49mend_page,\n\u001b[0;32m    176\u001b[0m     ocr\u001b[39m=\u001b[39;49mocr,\n\u001b[0;32m    177\u001b[0m     ocr_language\u001b[39m=\u001b[39;49mocr_language,\n\u001b[0;32m    178\u001b[0m     multiprocessing\u001b[39m=\u001b[39;49mmultiprocessing,\n\u001b[0;32m    179\u001b[0m )\n\u001b[0;32m    181\u001b[0m cleaned_pages \u001b[39m=\u001b[39m []\n\u001b[0;32m    182\u001b[0m \u001b[39mfor\u001b[39;00m page \u001b[39min\u001b[39;00m pages:\n",
      "File \u001b[1;32mc:\\Users\\jslug\\OneDrive\\Documents\\Anyone\\financial-advisor-chatbot\\.venv\\Lib\\site-packages\\haystack\\nodes\\file_converter\\pdf.py:299\u001b[0m, in \u001b[0;36mPDFToTextConverter._read_pdf\u001b[1;34m(self, file_path, ocr_language, sort_by_position, start_page, end_page, ocr, multiprocessing)\u001b[0m\n\u001b[0;32m    296\u001b[0m parts \u001b[39m=\u001b[39m divide(cpu, page_list)\n\u001b[0;32m    297\u001b[0m pages_mp \u001b[39m=\u001b[39m [(i, file_path, parts, sort_by_position, ocr, ocr_language) \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(cpu)]\n\u001b[1;32m--> 299\u001b[0m \u001b[39mwith\u001b[39;49;00m ProcessPoolExecutor(max_workers\u001b[39m=\u001b[39;49mcpu) \u001b[39mas\u001b[39;49;00m pool:\n\u001b[0;32m    300\u001b[0m     results \u001b[39m=\u001b[39;49m pool\u001b[39m.\u001b[39;49mmap(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_text_parallel, pages_mp)\n\u001b[0;32m    301\u001b[0m     \u001b[39mfor\u001b[39;49;00m page \u001b[39min\u001b[39;49;00m results:\n",
      "File \u001b[1;32mC:\\Program Files\\Python311\\Lib\\concurrent\\futures\\_base.py:647\u001b[0m, in \u001b[0;36mExecutor.__exit__\u001b[1;34m(self, exc_type, exc_val, exc_tb)\u001b[0m\n\u001b[0;32m    646\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__exit__\u001b[39m(\u001b[39mself\u001b[39m, exc_type, exc_val, exc_tb):\n\u001b[1;32m--> 647\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mshutdown(wait\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[0;32m    648\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mFalse\u001b[39;00m\n",
      "File \u001b[1;32mC:\\Program Files\\Python311\\Lib\\concurrent\\futures\\process.py:825\u001b[0m, in \u001b[0;36mProcessPoolExecutor.shutdown\u001b[1;34m(self, wait, cancel_futures)\u001b[0m\n\u001b[0;32m    822\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_executor_manager_thread_wakeup\u001b[39m.\u001b[39mwakeup()\n\u001b[0;32m    824\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_executor_manager_thread \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m wait:\n\u001b[1;32m--> 825\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_executor_manager_thread\u001b[39m.\u001b[39;49mjoin()\n\u001b[0;32m    826\u001b[0m \u001b[39m# To reduce the risk of opening too many files, remove references to\u001b[39;00m\n\u001b[0;32m    827\u001b[0m \u001b[39m# objects that use file descriptors.\u001b[39;00m\n\u001b[0;32m    828\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_executor_manager_thread \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[1;32mC:\\Program Files\\Python311\\Lib\\threading.py:1112\u001b[0m, in \u001b[0;36mThread.join\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m   1109\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mcannot join current thread\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m   1111\u001b[0m \u001b[39mif\u001b[39;00m timeout \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m-> 1112\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_wait_for_tstate_lock()\n\u001b[0;32m   1113\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1114\u001b[0m     \u001b[39m# the behavior of a negative timeout isn't documented, but\u001b[39;00m\n\u001b[0;32m   1115\u001b[0m     \u001b[39m# historically .join(timeout=x) for x<0 has acted as if timeout=0\u001b[39;00m\n\u001b[0;32m   1116\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_wait_for_tstate_lock(timeout\u001b[39m=\u001b[39m\u001b[39mmax\u001b[39m(timeout, \u001b[39m0\u001b[39m))\n",
      "File \u001b[1;32mC:\\Program Files\\Python311\\Lib\\threading.py:1132\u001b[0m, in \u001b[0;36mThread._wait_for_tstate_lock\u001b[1;34m(self, block, timeout)\u001b[0m\n\u001b[0;32m   1129\u001b[0m     \u001b[39mreturn\u001b[39;00m\n\u001b[0;32m   1131\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 1132\u001b[0m     \u001b[39mif\u001b[39;00m lock\u001b[39m.\u001b[39;49macquire(block, timeout):\n\u001b[0;32m   1133\u001b[0m         lock\u001b[39m.\u001b[39mrelease()\n\u001b[0;32m   1134\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stop()\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "preprocess_data_raw_2.convert_pdf_jason(config.DATA_RAW_PATH, config.DATA_PROCESSED_PATH)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generated the Elastisearch document store\n",
    "Before we need to run the elastisearch container using just once:\n",
    "\n",
    "**docker pull docker.elastic.co/elasticsearch/elasticsearch:7.9.2**\n",
    "\n",
    "And then run image:\n",
    "\n",
    "**docker run -d -p 9200:9200 -e \"discovery.type=single-node\" elasticsearch:7.9.2**\n",
    "\n",
    "You can do this manually, or using our [launch_es()](https://docs.haystack.deepset.ai/reference/utils-api) utility function.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the host where Elasticsearch is running, default to localhost\n",
    "host = os.environ.get(\"ELASTICSEARCH_HOST\", \"localhost\")\n",
    "\n",
    "document_store = ElasticsearchDocumentStore(\n",
    "    host=host,\n",
    "    username=\"\",\n",
    "    password=\"\",\n",
    "    index=\"document\"\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load dataset from json_dataset.json "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_file_path = os.path.join(config.DATA_PROCESSED_PATH, \"json_dataset.json\")\n",
    "# Load the documents from the JSON file\n",
    "with open(json_file_path, \"r\") as f:\n",
    "    document_list = json.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "document_list[0]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-processing and loading into the database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d023bfe4ab1247be97d141deb610caf5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Preprocessing:   0%|          | 0/10 [00:00<?, ?docs/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "We found one or more sentences whose word count is higher than the split length.\n",
      "Document 58149ab146d0b3889605e662512296b9 is 27615 characters long after preprocessing, where the maximum length should be 10000. Something might be wrong with the splitting, check the document affected to prevent issues at query time.\n",
      "Document cf8c146f296576b1988b1cefaac9f500 is 320800 characters long after preprocessing, where the maximum length should be 10000. Something might be wrong with the splitting, check the document affected to prevent issues at query time.\n"
     ]
    }
   ],
   "source": [
    "# Create an instance of PreProcessor\n",
    "# Each document is divided into paragraphs of approximately 500 tokens.\n",
    "\n",
    "preprocessor = PreProcessor(\n",
    "    clean_empty_lines=True,\n",
    "    clean_whitespace=True,\n",
    "    clean_header_footer=True,\n",
    "    split_by=\"word\",\n",
    "    split_length=500,\n",
    "    split_overlap=20,\n",
    "    split_respect_sentence_boundary=True,\n",
    ")\n",
    "\n",
    "doc_processed = preprocessor.process(document_list)\n",
    "\n",
    "# clear the document store before loading documents\n",
    "document_store.delete_documents()\n",
    "\n",
    "# Upload documents to the document store\n",
    "document_store.write_documents(doc_processed)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_processed[0]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate retriver and PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from haystack.nodes import BM25Retriever\n",
    "# Create an instance of BM25Retriver to select top_k better documents into document_store\n",
    "retriever = BM25Retriever(document_store=document_store, top_k = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from haystack.nodes import PromptTemplate\n",
    "\n",
    "# Create an instance of PromTemplate, we use the type question-answering\n",
    "qa_prompt = PromptTemplate(\n",
    "            name=\"question-answering\",\n",
    "            prompt_text=\"\"\"Given the context please answer the question. \n",
    "            Your answer should be in your own words and be no longer than 50 words. \n",
    "            Context: {join(documents)}; \n",
    "            Question:  {query}; Answer:\"\"\",\n",
    "                    )\n",
    "\n",
    "#prompt_node = PromptNode(model_name_or_path=\"google/flan-t5-large\", default_prompt_template=lfqa_prompt)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using GPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from haystack.nodes import PromptNode\n",
    "\n",
    "# Create an instance of PromptNode using ChatGPT API as generator\n",
    "generator = PromptNode(\"gpt-3.5-turbo\", \n",
    "                         api_key = config.API_KEY,\n",
    "                         default_prompt_template = qa_prompt,\n",
    "                         model_kwargs={\"stream\":True}) \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipeline Retriver-Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline()\n",
    "pipe.add_node(component=retriever, name=\"retriever\", inputs=[\"Query\"])\n",
    "pipe.add_node(component=generator, name=\"generator\", inputs=[\"retriever\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AMERI Holdings provides SAP cloud, digital and enterprise services to clients worldwide, with a primary business objective of enhancing their clients' business capabilities and technologies through consulting services and strategic acquisitions.[\"AMERI Holdings provides SAP cloud, digital and enterprise services to clients worldwide, with a primary business objective of enhancing their clients' business capabilities and technologies through consulting services and strategic acquisitions.\"]\n"
     ]
    }
   ],
   "source": [
    "# Queries examples: use some companie name\n",
    "output = pipe.run(query=\"What is the company AMERI Holdings dedicated to?\", \n",
    "                      params={\"retriever\": {\"top_k\": 2},}) # Set params value is optative, because top_k was fixed as 5 before\n",
    "print(output['results'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
