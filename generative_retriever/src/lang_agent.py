from langchain.chat_models import ChatOpenAI
from langchain.chains import RetrievalQA
from langchain.agents import initialize_agent, Tool
from src import settings
from src.utils import make_retriever


llm = ChatOpenAI(
    openai_api_key=settings.API_KEY,
    model_name="gpt-3.5-turbo",
    temperature=0.0,
)

# retrieval qa chain
qa = RetrievalQA.from_chain_type(
    llm=llm, chain_type="stuff", retriever=make_retriever()
)

SUFFIX = """Begin! Take into consideration the previous chat history (if not empty): {chat_history}. Reminder to ALWAYS respond with a valid json blob of a single action. Use tools if necessary. Respond directly without using any tool if appropriate. Format is Action:```$JSON_BLOB```then Observation:.
Thought:"""


def make_agent():
    tools = [
        Tool(
            name="Knowledge Base",
            func=qa.run,
            description=(
                "Use this tool first and only once per input question when answering complex queries about companies to get "
                "more information about the topic. Run the query exactly as written, "
                "except if previous chat history is not empty. "
                "In that case, run the query according to the previous chat history."
            ),
        ),
        Tool(
            name="BM25 Retrieval",
            func=qa.run,
            description=(
                "Use this tool IF AND ONLY IF the answer generated by the "
                "<Knowledge Base> tool does not contain relevant information for the query. "
                "Do not run the query exactly as it was written. "
                "The 'tool_input' should use relevant keywords for a BM25 algorithm. "
                "Do not omit important input details such as dates, numbers, company names or acronyms; "
                "especially if the acronyms are written between parenthesis, for example: (DOO)."
            ),
        ),
    ]

    agent = initialize_agent(
        agent="structured-chat-zero-shot-react-description",
        tools=tools,
        llm=llm,
        max_iterations=2,
        early_stopping_method="generate",
        agent_kwargs={
            "suffix": SUFFIX,
            "input_variables": ["input", "agent_scratchpad", "chat_history"],
        },
    )
    return agent
